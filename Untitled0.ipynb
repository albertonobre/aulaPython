{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1x8z7i-NZcj5r51TypxsFKbsr3x27PyJs",
      "authorship_tag": "ABX9TyPDo1IaNRYwI1s15yNk3q+P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/albertonobre/aulaPython/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "url = \"https://www.capivararota.com/\"\n",
        "\n",
        "page = requests.get(url)\n",
        "\n",
        "print(page)\n",
        "\n",
        "soup = BeautifulSoup(page.text, 'html')\n",
        "\n",
        "meta = soup.find_all('meta')\n",
        "\n",
        "for x in meta:\n",
        "  print(x)\n"
      ],
      "metadata": {
        "id": "-d2pVMlmAeT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests"
      ],
      "metadata": {
        "id": "Og2BLLmF_Wp5"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "GEiX83JQu2Lb"
      },
      "outputs": [],
      "source": [
        "url = 'https://www.scrapethissite.com/pages/forms'\n",
        "\n",
        "page = requests.get(url)\n",
        "#print(page) # trás o código <Reponse [200]> se deu certo\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "soup = BeautifulSoup(page.text , 'html')\n",
        "\n",
        "print(soup)\n"
      ],
      "metadata": {
        "id": "21akQG-u_nDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "title = soup.find_all('title')\n",
        "print(title)\n",
        "\n",
        "tabela = soup.find('table')\n",
        "tr_titulos = tabela.find('tr')\n",
        "\n",
        "print(tr_titulos)\n"
      ],
      "metadata": {
        "id": "uDRsC17s_syx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "team = soup.find_all(\"td\" , class_='name')\n",
        "#print(team)\n",
        "\n",
        "nomesTimes = [x.text.strip() for x in team]  # \"x.text.strip()\" : recorta somente os textos, não tras a tag html\n",
        "print(nomesTimes)\n",
        "for x in nomesTimes:\n",
        "  print(x)\n"
      ],
      "metadata": {
        "id": "HrH4Bn5yHTKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Buscando imagens do site https://www.capivararota.com/\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = \"https://www.capivararota.com/\"\n",
        "\n",
        "page = requests.get(url)\n",
        "\n",
        "soup = BeautifulSoup(page.text, 'html')\n",
        "\n",
        "images = soup.find_all('img')\n",
        "\n",
        "for image in images:\n",
        "  print(image['src'])\n"
      ],
      "metadata": {
        "id": "x1yFqgotT6yV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "\n",
        "# URL do site\n",
        "url = \"https://www.capivararota.com/\"\n",
        "\n",
        "# Obtendo o conteúdo HTML da página\n",
        "response = requests.get(url)\n",
        "html_content = response.text\n",
        "\n",
        "# Parseando o HTML com BeautifulSoup\n",
        "soup = BeautifulSoup(html_content, \"html.parser\")\n",
        "\n",
        "# Encontrando todas as tags de imagem (<img>) na página\n",
        "images = soup.find_all(\"img\")\n",
        "\n",
        "# Diretório para salvar as imagens (se não existir, cria o diretório)\n",
        "save_directory = \"imagens_capivara\"\n",
        "if not os.path.exists(save_directory):\n",
        "    os.makedirs(save_directory)\n",
        "\n",
        "# Baixando e salvando as imagens\n",
        "for img in images:\n",
        "    img_url = img.get(\"src\")\n",
        "    if img_url:\n",
        "        img_name = img_url.split(\"/\")[-1]\n",
        "        img_data = requests.get(img_url).content\n",
        "        with open(os.path.join(save_directory, img_name), \"wb\") as img_file:\n",
        "            img_file.write(img_data)\n",
        "\n",
        "print(\"Imagens baixadas com sucesso!\")\n"
      ],
      "metadata": {
        "id": "Pq7vEUx9Wo7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# URL do site\n",
        "url = \"https://www.capivararota.com/\"\n",
        "\n",
        "# Obtendo o conteúdo HTML da página\n",
        "response = requests.get(url)\n",
        "html_content = response.text\n",
        "\n",
        "# Parseando o HTML com BeautifulSoup\n",
        "soup = BeautifulSoup(html_content, \"html.parser\")\n",
        "\n",
        "# Encontrando todas as tags de imagem (<img>) na página\n",
        "images = soup.find_all(\"img\")\n",
        "\n",
        "# Exibindo os links das imagens encontradas\n",
        "for img in images:\n",
        "    img_url = img.get(\"src\")\n",
        "    if img_url:\n",
        "        print(img_url)\n"
      ],
      "metadata": {
        "id": "HtGA0UYEZFgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "url = \"https://economia.uol.com.br/cotacoes/cambio/\"\n",
        "\n",
        "page = requests.get(url)\n",
        "\n",
        "soup = BeautifulSoup(page.text, 'html')\n",
        "\n",
        "cotacaoDolar = soup.find(\"span\", class_=\"value bra\")\n",
        "print(cotacaoDolar)\n",
        "\n"
      ],
      "metadata": {
        "id": "gxUaJ_02bE9b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}